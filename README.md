# apache-spark-hadoop
use apache-spark-hadoop to do word count on anagrams and palindrome from a dataset

## Apache-spark
Spark-python
* Run spark on entire dataset except the invalid list
    - spark-submit test.py

* Run spark on invalid list invididually
    - spark-submit test_words.py

* Run spark on invalid list and go into subdirectory invididually
    - spark-submit test_JSON.py

* UPDATE and Combine invalid results
    - python test_updateJSON.py

* Combine resultes of valid and invalid 
    - python test_combineJSON.py

* Output results
    - python test_OutputFiles.py


